{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/serge-m/pytorch-nn-tools.git@master\n",
    "# !pip install pytorch-nn-tools==0.3.7\n",
    "# !pip install torch_lr_finder==0.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U albumentations==0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser, Namespace\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Callable, Union\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "from pytorch_nn_tools.visual import ImgShow, tfm_vis_img, UnNormalize_, imagenet_stats\n",
    "from pytorch_nn_tools.train.metrics.processor import mod_name_train, mod_name_val, Marker\n",
    "from pytorch_nn_tools.train.metrics.processor import MetricAggregator, TensorBoardMetricLogger\n",
    "from pytorch_nn_tools.metrics.accuracy import topk_accuracy\n",
    "from pytorch_nn_tools.train.progress import ProgressTracker\n",
    "from pytorch_nn_tools.convert import map_dict\n",
    "from pytorch_nn_tools.train.metrics.history_condition import HistoryCondition\n",
    "from pytorch_nn_tools.devices import to_device\n",
    "import ml_dataset_tools as mdt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer.trainer_io import TrainerIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ish = ImgShow(ax=plt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8\n",
    "\n",
    "batch_size_train, batch_size_val, device = 2, 2, 'cpu'\n",
    "batch_size_train, batch_size_val, device = 128, 128, 'cuda'\n",
    "\n",
    "data_root_path = Path(\"data/\")\n",
    "data_path = data_root_path.joinpath(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_h_w = 224, 224\n",
    "\n",
    "imagenet_stats = dict(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "\n",
    "cifar_stats = dict(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(**cifar_stats),\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(**cifar_stats),\n",
    "])\n",
    "\n",
    "\n",
    "ds_tr  = datasets.CIFAR10(root=data_root_path, train=True, download=True, transform=transform_train)\n",
    "ds_val = datasets.CIFAR10(root=data_root_path, train=False, download=False, transform=transform_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=ds_tr,\n",
    "        batch_size=batch_size_train,\n",
    "        shuffle=True, \n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    \n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=ds_val,\n",
    "        batch_size=batch_size_val,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_images(tb_writer, images, iteration_id):\n",
    "    with torch.no_grad():\n",
    "        vis = images.detach().clone()\n",
    "        for v in vis:\n",
    "            v[:] = UnNormalize_(**cifar_stats)(v)\n",
    "        grid = torchvision.utils.make_grid(vis)\n",
    "        tb_writer.add_image('images', grid, iteration_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = torch.tensor([\n",
    "#     [0.1, 0.7, 0.2],\n",
    "#     [0.6, 0.3, 0.1],\n",
    "#     [0.05, 0.05, 0.05],\n",
    "#     [5, 0.01, 0.0]\n",
    "# ])\n",
    "# confidence = torch.tensor([\n",
    "#     0.99, 0.01, 0.99, 0.01 \n",
    "# ])\n",
    "# # output = torch.tensor([\n",
    "# #     [0.0, 1., 0.0],\n",
    "# #     [1., 0.0, 0.0]\n",
    "# # ])\n",
    "# target = torch.tensor([2, 2, 0, 0])\n",
    "# F.cross_entropy(output, target, reduction='none'), F.cross_entropy(output, target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F.cross_entropy(output, target, reduction='none') * confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idxs = torch.stack(\n",
    "#     (\n",
    "#         torch.arange(target.size(0)), \n",
    "#         target\n",
    "#     ),\n",
    "#     dim=1\n",
    "# )\n",
    "# idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_vals, t_ids = output.topk(1, dim=1)\n",
    "# t_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = output.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.topk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.log_softmax(axis=1).topk(k=1, dim=1)[0].exp(), 1./output.size(1)\n",
    "# .exp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (output.exp() / output.exp().sum(axis=1, keepdims=True)).log()# - output.log_softmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 2\n",
    "# (output[i].exp() / output[i].exp().sum()).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.log_softmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F.nll_loss(F.log_softmax(output, dim=1), target, reduction='none').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, device, trainer_io: TrainerIO,\n",
    "                continue_training: bool = False):\n",
    "        self.device = device\n",
    "        self.continue_training = continue_training\n",
    "        self.trainer_io = trainer_io\n",
    "        \n",
    "    def fit(self, models, optimizers, schedulers, start_epoch, end_epoch, train_dataloader, val_dataloader):\n",
    "        metric_logger = TensorBoardMetricLogger(self.trainer_io.tb_summary_writer)\n",
    "        models = to_device(models, self.device)\n",
    "        \n",
    "        if self.continue_training:\n",
    "            start_epoch = self.trainer_io.load_last(start_epoch, end_epoch, model, optimizer, scheduler)\n",
    "\n",
    "        progr_train = ProgressTracker()\n",
    "        \n",
    "        for epoch in self.trainer_io.main_progress_bar(range(start_epoch, end_epoch)):\n",
    "            metric_aggregator = MetricAggregator()\n",
    "            self.train_epoch(\n",
    "                train_dataloader, progr_train,\n",
    "                models, optimizers, schedulers,  \n",
    "                metric_proc=mod_name_train+metric_aggregator+metric_logger,\n",
    "                report_step=100,\n",
    "            )\n",
    "            self.validate_epoch(\n",
    "                val_dataloader,\n",
    "                models,  \n",
    "                metric_proc=mod_name_val+metric_aggregator+metric_logger,\n",
    "            )\n",
    "            \n",
    "            aggregated = map_dict(metric_aggregator.aggregate(), key_fn=lambda key: f\"avg.{key}\")\n",
    "            metric_logger({\n",
    "                **aggregated, \n",
    "                **{f\"lr_small_{i}\": lr for i, lr in enumerate(schedulers['small'].get_last_lr())},\n",
    "                **{f\"lr_large_{i}\": lr for i, lr in enumerate(schedulers['large'].get_last_lr())},\n",
    "                Marker.EPOCH: epoch,\n",
    "            })\n",
    "            self.trainer_io.set_main_status_msg(f\"{aggregated}\")\n",
    "#             self.trainer_io.save_checkpoint(aggregated, model, optimizer, scheduler, epoch)\n",
    "            \n",
    "        metric_logger.close()\n",
    "            \n",
    "    def train_epoch(self, data_loader, progr, models, optimizers, schedulers, metric_proc, report_step):\n",
    "        for model in models.values():\n",
    "            model.train()\n",
    "                \n",
    "        for batch in self.trainer_io.secondary_progress_bar(progr.track(data_loader)):\n",
    "            batch = to_device(batch, self.device)\n",
    "            images, target = batch\n",
    "\n",
    "            optimizers['small'].zero_grad()\n",
    "                        \n",
    "            output_small = models['small'](images)\n",
    "            confidence = output_small.log_softmax(axis=1).topk(k=1, dim=1)[0].exp()\n",
    "            min_confidence = output_small.size(1)\n",
    "            confidence = (confidence - min_confidence) / (1. - min_confidence) # scale from 0 to 1\n",
    "            \n",
    "            \n",
    "            optimizers['large'].zero_grad()\n",
    "            output_large = models['large'](images)\n",
    "            loss_large = F.cross_entropy(output_large, target, reduction='none') \n",
    "            loss_large_with_confidence = (loss_large * (1.-confidence.detach())).mean()\n",
    "            loss_large_with_confidence.backward()\n",
    "            optimizers['large'].step()\n",
    "                \n",
    "            # TODO: understand how to apply weight for different items in a batch\n",
    "            loss_small = (\n",
    "                (\n",
    "                    F.cross_entropy(output_small, target, reduction='none') * confidence\n",
    "                ) + \n",
    "                (1-confidence) * loss_large.detach()\n",
    "            ).mean()\n",
    "            loss_small.backward()\n",
    "            \n",
    "            optimizers['small'].step()\n",
    "            schedulers['large'].step()\n",
    "            schedulers['small'].step()\n",
    "            \n",
    "            if progr.cnt_total_iter % report_step == 0:\n",
    "                with torch.no_grad():\n",
    "                    acc_small = topk_accuracy(output_small, target, topk=(1,))[0]\n",
    "                    acc_large = topk_accuracy(output_large, target, topk=(1,))[0]\n",
    "\n",
    "                    metric_proc({\n",
    "                        'loss_small': loss_small, \n",
    "                        'loss_large': loss_large.mean(), \n",
    "                        'loss_large_with_confidence': loss_large_with_confidence, \n",
    "                        'acc_small': acc_small, \n",
    "                        'acc_large': acc_large, \n",
    "                        Marker.ITERATION: progr.cnt_total_iter,\n",
    "                        \n",
    "                    })\n",
    "\n",
    "#             if batch_idx == 0 and tb_writer:\n",
    "#                 publish_images(tb_writer, images, progr.cnt_total_iter)\n",
    "            \n",
    "#         scheduler.step()\n",
    "\n",
    "            \n",
    "\n",
    "    def validate_epoch(self, data_loader, models, metric_proc):\n",
    "        for model in models.values():\n",
    "            model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.trainer_io.secondary_progress_bar(data_loader):\n",
    "                batch = to_device(batch, self.device)\n",
    "                images, target = batch\n",
    "                output_small = models['small'](images)\n",
    "                loss_small = F.cross_entropy(output_small, target)\n",
    "                acc_small = topk_accuracy(output_small, target, topk=(1, ))[0]\n",
    "                metric_proc({'loss_small': loss_small, 'acc_small': acc_small})\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net import preact_resnet_from_pytorch_cifar \n",
    "# model = preact_resnet_from_pytorch_cifar.PreActResNet(preact_resnet_from_pytorch_cifar.PreActBlock, [2, 2, 2, 2])\n",
    "def build_model():\n",
    "    return {\n",
    "        'small': preact_resnet_from_pytorch_cifar.PreActResNet(preact_resnet_from_pytorch_cifar.PreActBlock, [1, 1, 1, 1], num_planes=[64,64,64,64]),\n",
    "        'large': preact_resnet_from_pytorch_cifar.PreActResNet(preact_resnet_from_pytorch_cifar.PreActBlock, [2, 2, 2, 2])\n",
    "    }\n",
    "\n",
    "\n",
    "model = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = model['small']\n",
    "# m.to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model['small'], input_size=(3, 32, 32), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "\n",
    "num_epochs = 50\n",
    "optimizers = {\n",
    "    \n",
    "\n",
    "    'small': torch.optim.SGD([\n",
    "        {\n",
    "            'params': model['small'].parameters(), \n",
    "            'lr': recommended_lr,\n",
    "            'momentum' :0.9, \n",
    "            'weight_decay': 5e-4\n",
    "        }\n",
    "    ]),\n",
    "    'large': torch.optim.SGD([\n",
    "        {\n",
    "            'params': model['large'].parameters(), \n",
    "            'lr': recommended_lr,\n",
    "            'momentum' :0.9, \n",
    "            'weight_decay': 5e-4\n",
    "        }\n",
    "    ]),\n",
    "}\n",
    "    \n",
    "\n",
    "schedulers = {\n",
    "    \n",
    "    'small': torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizers['small'],\n",
    "        max_lr=recommended_lr,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=len(train_dataloader),\n",
    "        pct_start=0.1,\n",
    "    ),\n",
    "    'large': torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizers['large'],\n",
    "        max_lr=recommended_lr,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=len(train_dataloader),\n",
    "        pct_start=0.1,\n",
    "    ),\n",
    "}\n",
    "\n",
    "trainer_io = TrainerIO(\n",
    "    log_dir=\"./logs/\", experiment_name=f\"cifar10_multistage_1_lr{recommended_lr}_sgdarr_onecpct0.1\", \n",
    "    checkpoint_condition=HistoryCondition(\n",
    "        'avg.val.acc1', \n",
    "        lambda hist: len(hist) == 1 or hist[-1] > max(hist[:-1])\n",
    "    )\n",
    ")\n",
    "\n",
    "trainer = Trainer(device=device, trainer_io=trainer_io, continue_training=False)\n",
    "\n",
    "trainer.fit(\n",
    "    model, optimizers, schedulers,\n",
    "    start_epoch=0, end_epoch=num_epochs,\n",
    "#     train_dataloader=list(islice(train_dataloader, 0, 10)), \n",
    "#     val_dataloader=list(islice(val_dataloader, 0, 10)),\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !rm checkpoints/epoch_00001*\n",
    "# !rm checkpoints/epoch_00002*\n",
    "# !rm checkpoints/epoch_00003*\n",
    "# !rm logs/experiment1/checkpoints/epoch_00004*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
