{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/serge-m/pytorch-nn-tools.git@v0.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser, Namespace\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from pytorch_lightning.callbacks import LearningRateLogger\n",
    "import numpy as np\n",
    "\n",
    "from model_base import ModelBase, get_main_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Callable, Union\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from time import sleep\n",
    "\n",
    "import pytorch_nn_tools as pnt\n",
    "from pytorch_nn_tools.visual import ImgShow\n",
    "from pytorch_nn_tools.train.metrics.processor import mod_name_train, mod_name_val, Marker\n",
    "from pytorch_nn_tools.train.metrics.processor import MetricAggregator, MetricLogger\n",
    "from pytorch_nn_tools.train.progress import ProgressTracker\n",
    "from pytorch_nn_tools.convert import map_dict\n",
    "from pytorch_nn_tools.train.metrics.history_condition import HistoryCondition\n",
    "from pytorch_nn_tools.train.checkpoint import CheckpointSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ish = ImgShow(ax=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_dataset(path):\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "\n",
    "    train_dir = os.path.join(path, 'train')\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        train_dir,\n",
    "        transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "def _val_dataset(path):\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "    val_dir = os.path.join(path, 'val')\n",
    "    dataset = datasets.ImageFolder(val_dir, transforms.Compose(\n",
    "        [transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), normalize, ]))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8\n",
    "\n",
    "batch_size_train = 2\n",
    "batch_size_val = 2\n",
    "# batch_size_train = 128\n",
    "# batch_size_val = 16\n",
    "\n",
    "\n",
    "data_path = \"data/imagewoof2-320-cut/\"\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=_train_dataset(data_path),\n",
    "        batch_size=batch_size_train,\n",
    "        shuffle=True, \n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    \n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=_val_dataset(data_path),\n",
    "        batch_size=batch_size_val,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(batch, device):\n",
    "    return batch.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprogress.fastprogress import master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def now_as_str():\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%Y%m%d_%H%M%s_%f\")\n",
    "\n",
    "class PBars:\n",
    "    def __init__(self):\n",
    "        self._main = None\n",
    "        self._second = None\n",
    "        \n",
    "    def main(self, it, **kwargs):\n",
    "        self._main = master_bar(it, **kwargs)\n",
    "        return self._main\n",
    "    \n",
    "    def secondary(self, it, **kwargs):\n",
    "        if self._main is None:\n",
    "            raise RuntimeError(\"Cannot instantiate secondary progress bar. The main progress bar is not set.\")\n",
    "        self._second = progress_bar(it, parent=self._main, **kwargs)\n",
    "        return self._second\n",
    "        \n",
    "    def main_comment(self, comment):\n",
    "        self._main.main_bar.comment = comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, device, checkpoint_saver, checkpoint_condition,\n",
    "                continue_training: bool = False,\n",
    "                log_dir=\"./logs\",\n",
    "                name=\"model\"):\n",
    "        self.device = device\n",
    "        self.checkpoint_condition = checkpoint_condition\n",
    "        self.checkpoint_saver = checkpoint_saver\n",
    "        self.continue_training = continue_training\n",
    "        self.log_dir = Path(log_dir)\n",
    "        self.name = name\n",
    "        self.pbars = PBars()\n",
    "        \n",
    "        \n",
    "    def fit(self, model, optimizer, scheduler, start_epoch, end_epoch):\n",
    "        path_logs = Path(self.log_dir).joinpath(f\"{self.name}_{now_as_str()}\")\n",
    "        metric_logger = MetricLogger(path_logs)\n",
    "        model = model.to(self.device)\n",
    "        \n",
    "        if self.continue_training:\n",
    "            last = self.checkpoint_saver.find_last(start_epoch, end_epoch)\n",
    "            if last is not None:\n",
    "                print(f\"found pretrained results for epoch {last}. Loading...\")\n",
    "                self.checkpoint_saver.load(model, optimizer, scheduler, last)\n",
    "                start_epoch = last + 1\n",
    "\n",
    "        progr_train = ProgressTracker()\n",
    "        \n",
    "        for epoch in self.pbars.main(range(start_epoch, end_epoch)):\n",
    "            metric_aggregator = MetricAggregator()\n",
    "            self.train_epoch(\n",
    "                train_dataloader, progr_train,\n",
    "                model, optimizer, scheduler,  \n",
    "                metric_proc=mod_name_train+metric_aggregator+metric_logger,\n",
    "                pbars=self.pbars,\n",
    "                report_step=10\n",
    "            )\n",
    "            self.validate_epoch(\n",
    "                val_dataloader,\n",
    "                model,  \n",
    "                metric_proc=mod_name_val+metric_aggregator+metric_logger,\n",
    "                pbars=self.pbars,\n",
    "            )\n",
    "            aggregated = map_dict(metric_aggregator.aggregate(), key_fn=lambda key: f\"avg.{key}\")\n",
    "            metric_logger({**aggregated, Marker.EPOCH: epoch})\n",
    "            self.pbars.main_comment(f\"{aggregated}\")\n",
    "            \n",
    "            scheduler.step()\n",
    "                        \n",
    "            if self.checkpoint_condition(aggregated): \n",
    "                self.checkpoint_saver.save(model, optimizer, scheduler, epoch)\n",
    "            \n",
    "            metric_logger.close()\n",
    "        return path_logs\n",
    "            \n",
    "    def train_epoch(self, data_loader, progr, model, optimizer, scheduler, metric_proc, pbars, report_step=1):\n",
    "        model.train()\n",
    "                \n",
    "        for images, target in progr.track(pbars.secondary(data_loader)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            images = to_device(images, self.device)\n",
    "            target = to_device(target, self.device)\n",
    "            \n",
    "            output = model(images)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if progr.cnt_total_iter % report_step == 0:\n",
    "                with torch.no_grad():\n",
    "                    acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "                metric_proc({'loss': loss, 'acc1': acc1, 'acc5': acc5, Marker.ITERATION: progr.cnt_total_iter})\n",
    "                    \n",
    "        \n",
    "        \n",
    "    def validate_epoch(self, data_loader, model, metric_proc, pbars):\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, target in pbars.secondary(data_loader):\n",
    "                images = to_device(images, self.device)\n",
    "                target = to_device(target, self.device)\n",
    "\n",
    "                output = model(images)\n",
    "                loss = F.cross_entropy(output, target)\n",
    "                acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "                \n",
    "                metric_proc(dict(loss=loss, acc1=acc1, acc5=acc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm checkpoints/epo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='18' class='' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      22.50% [18/80 00:25<01:28 {'avg.val.loss': 106.88151297569274, 'avg.val.acc1': 50.0, 'avg.val.acc5': 100.0}]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/3 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model to checkpoints/epoch_00000.pth\n",
      "saving optimizer state to checkpoints/epoch_00000.optimizer.pth\n",
      "saving scheduler state to checkpoints/epoch_00000.scheduler.pth\n",
      "saving meta data to checkpoints/epoch_00000.meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/work/nn/.venv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model to checkpoints/epoch_00002.pth\n",
      "saving optimizer state to checkpoints/epoch_00002.optimizer.pth\n",
      "saving scheduler state to checkpoints/epoch_00002.scheduler.pth\n",
      "saving meta data to checkpoints/epoch_00002.meta.json\n",
      "saving model to checkpoints/epoch_00017.pth\n",
      "saving optimizer state to checkpoints/epoch_00017.optimizer.pth\n",
      "saving scheduler state to checkpoints/epoch_00017.scheduler.pth\n",
      "saving meta data to checkpoints/epoch_00017.meta.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-52b2d5b6adf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m trainer.fit(\n\u001b[1;32m     29\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-12-da7d188cc487>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, optimizer, scheduler, start_epoch, end_epoch)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mmetric_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmod_name_train\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmetric_aggregator\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmetric_logger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mpbars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mreport_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             )\n\u001b[1;32m     38\u001b[0m             self.validate_epoch(\n",
      "\u001b[0;32m<ipython-input-12-da7d188cc487>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, data_loader, progr, model, optimizer, scheduler, metric_proc, pbars, report_step)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprogr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnt_total_iter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreport_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/nn/.venv/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/nn/.venv/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)        \n",
    "        \n",
    "checkpoint_condition = HistoryCondition(\n",
    "    'avg.val.acc1', \n",
    "    lambda hist: len(hist) == 1 or hist[-1] > max(hist[:-1])\n",
    ")\n",
    "checkpoint_saver = CheckpointSaver(path=\"checkpoints\")\n",
    "trainer = Trainer(\n",
    "    device='cpu', checkpoint_saver=checkpoint_saver, checkpoint_condition=checkpoint_condition,\n",
    "    continue_training=True\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD([\n",
    "    {\n",
    "        'name': 'main_model',\n",
    "        'params': model.parameters(),\n",
    "        'lr': 0.1,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 1e-4,\n",
    "    }\n",
    "])\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lambda epoch: 0.1 ** (epoch // 30)\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model, optimizer, scheduler,\n",
    "    start_epoch=0, end_epoch=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
